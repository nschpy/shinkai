{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03933c5a",
   "metadata": {},
   "source": [
    "## Загрузка библиотек\n",
    "\n",
    "- unsloth\n",
    "- transformers\n",
    "- trl\n",
    "- peft\n",
    "- bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Install Unsloth, Xformers (Flash Attention) and more!\n",
    "\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c9d4d",
   "metadata": {},
   "source": [
    "## Импорт зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593588d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f5b46",
   "metadata": {},
   "source": [
    "## Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 1024\n",
    "dtype = torch.bfloat16\n",
    "load_in_4bit = False \n",
    "load_in_8bit = True \n",
    "full_finetuning = True\n",
    "test_size = 0.1\n",
    "\n",
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "cache_dir = \"/mode_cache/\"\n",
    "save_dir = f\"/outputs/{model_name}/tuned\"\n",
    "output_dir=f\"/outputs/{model_name}/outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811c195",
   "metadata": {},
   "source": [
    "## Загрузака модели и dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    load_in_8bit = load_in_8bit,\n",
    "    full_finetuning = full_finetuning\n",
    ")\n",
    "\n",
    "# Опционально снизить VRAM\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "RAW_IFT_LINK = \"https://raw.githubusercontent.com/nschpy/shinkai-dataset/refs/heads/main/ift.dataset.json\"\n",
    "\n",
    "ds = load_dataset(\"json\", data_files=RAW_IFT_LINK, cache_dir=cache_dir)\n",
    "ds = ds.train_test_split(test_size=test_size, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b6339",
   "metadata": {},
   "source": [
    "## Подготовка данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff39f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(batch):\n",
    "    return {\n",
    "        \"text\": [\n",
    "            f\"{input_text}\\n\\n{output_text}\"\n",
    "            for input_text, output_text in zip(batch[\"input\"], batch[\"output\"])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ✅ 2. Применение через map(..., batched=True)\n",
    "train_dataset = ds[\"train\"].map(formatting_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be110d",
   "metadata": {},
   "source": [
    "## Подготовка к SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6615b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 5. SFTConfig — указываем готовое поле text\n",
    "sft_config = SFTConfig(\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    packing = False,\n",
    "    learning_rate = 5e-5,\n",
    "    eos_token=tokenizer.eos_token,\n",
    "    pad_token=tokenizer.pad_token,\n",
    "    output_dir=\"\"\n",
    "    completion_only_loss = True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    output_dir=save_dir,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    seed= 42,\n",
    "    report_to = []\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    args = sft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62696ec",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050679f3",
   "metadata": {},
   "source": [
    "## Скачать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ed7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r model1.zip outputs/full_sft1/merged\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "files.download('model1.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shinkai-LYQ5IRPl-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
